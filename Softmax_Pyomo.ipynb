{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p><a href=\"https://colab.research.google.com/github/MIsaiko/SORCT_Pyomo/blob/main/Softmax_Pyomo.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>"
      ],
      "metadata": {
        "id": "mckTug9uDh9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "JuXrJMdLAr3H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "REWafWBGCe-F",
        "nbpages": {
          "level": 2,
          "link": "[7.1.1 Imports](https://jckantor.github.io/ND-Pyomo-Cookbook/07.01-Parameter-Estimation-Catalytic-Reactor.html#7.1.1-Imports)",
          "section": "7.1.1 Imports"
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import scipy.stats as stats\n",
        "import scipy.optimize as optimize\n",
        "\n",
        "import shutil\n",
        "import sys\n",
        "import os.path\n",
        "\n",
        "if not shutil.which(\"pyomo\"):\n",
        "    !pip install -q pyomo\n",
        "    assert(shutil.which(\"pyomo\"))\n",
        "\n",
        "if not (shutil.which(\"ipopt\") or os.path.isfile(\"ipopt\")):\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        !wget -N -q \"https://ampl.com/dl/open/ipopt/ipopt-linux64.zip\"\n",
        "        !unzip -o -q ipopt-linux64\n",
        "    else:\n",
        "        try:\n",
        "            !conda install -c conda-forge ipopt \n",
        "        except:\n",
        "            pass\n",
        "\n",
        "assert(shutil.which(\"ipopt\") or os.path.isfile(\"ipopt\"))\n",
        "\n",
        "from pyomo.environ import *\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Description"
      ],
      "metadata": {
        "id": "QzTzJPQvBJoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook uses optimization tools [Pyomo](http://www.pyomo.org/) to implement the logistic regression and softmax regression then tests it by using [The breast cancer dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) and [The Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)."
      ],
      "metadata": {
        "id": "YE2cR776BLcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression"
      ],
      "metadata": {
        "id": "i89_jnoFAwdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression(X, y, w_reg = 0.001):\n",
        "    n_instances, n_features = X.shape\n",
        "    \n",
        "    m = ConcreteModel()\n",
        "    \n",
        "    m.F = Set(initialize=list(range(n_features)))\n",
        "    m.I = Set(initialize=list(range(n_instances)))\n",
        "    \n",
        "    train_set = {(i, f): X[i,f] for i in m.I for f in m.F}\n",
        "    m.X = Param(m.I, m.F, within=Reals, initialize=train_set)\n",
        "    m.y = Param(m.I, within=Reals, initialize={i: y[i] for i in m.I})\n",
        "    \n",
        "    m.beta = Var(m.F, within=Reals)\n",
        "\n",
        "    def p_exp(model, i):\n",
        "      return 1.0 / (1.0 + exp(-1*sum(model.beta[f]*model.X[i, f] for f in model.F)))\n",
        "    m.p = Expression(m.I, rule=p_exp)\n",
        "    \n",
        "    # Objective:\n",
        "    def cost_rule(model):\n",
        "        cost = 0.0\n",
        "        for i in model.I:\n",
        "            cost += model.y[i]*log(model.p[i]) + (1.0-model.y[i])*log(1.0-model.p[i])\n",
        "        reg = w_reg*sum(model.beta[f]**2 for f in model.F) # Regularization\n",
        "        return -1*cost + reg\n",
        "    m.cost = Objective(rule=cost_rule, sense=minimize)\n",
        "\n",
        "    return m\n",
        "\n",
        "def lr_predict(model, X):\n",
        "  pred = []\n",
        "  for i in range(X.shape[0]):\n",
        "    pred.append(round(1.0 / (1.0 + np.exp(-1*sum(model.beta[f]()*X[i, f] for f in model.F)))))\n",
        "  return pred"
      ],
      "metadata": {
        "id": "UMqvPlc4abuz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax regression"
      ],
      "metadata": {
        "id": "hfogUZZAA3Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_regression(X, y, k, w_reg = 0.001):\n",
        "    n_instances, n_features = X.shape\n",
        "    \n",
        "    m = ConcreteModel()\n",
        "    \n",
        "    m.F = Set(initialize=list(range(n_features)))\n",
        "    m.I = Set(initialize=list(range(n_instances)))\n",
        "\n",
        "    m.k = Set(initialize=list(range(k)))\n",
        "    \n",
        "    train_set = {(i, f): X[i,f] for i in m.I for f in m.F}\n",
        "    m.X = Param(m.I, m.F, within=Reals, initialize=train_set)\n",
        "    m.y = Param(m.I, within=Reals, initialize={i: y[i] for i in m.I})\n",
        "    \n",
        "    m.beta = Var(m.k, m.F, within=Reals)\n",
        "\n",
        "    def p_exp(model, i, ki):\n",
        "        beta_list = []\n",
        "        for k_i in model.k:\n",
        "            beta_i = exp(sum(model.beta[k_i, f]*model.X[i, f] for f in model.F))\n",
        "            beta_list.append(beta_i)\n",
        "        return [b/sum(beta_list) for b in beta_list][ki]\n",
        "    m.p = Expression(m.I, m.k, rule=p_exp)\n",
        "    \n",
        "    # Objective:\n",
        "    def cost_rule(model):\n",
        "        cost = 0.0\n",
        "        for i in model.I:\n",
        "            for ki in model.k:\n",
        "                if model.y[i] == ki:\n",
        "                    cost += log(model.p[i,ki])\n",
        "        reg = w_reg*sum(model.beta[k_i,f]**2 for k_i in model.k for f in model.F)\n",
        "        return -1*cost + reg\n",
        "    m.cost = Objective(rule=cost_rule, sense=minimize)\n",
        "\n",
        "    return m\n",
        "\n",
        "def softmax_predict(model, X):\n",
        "    pred = []\n",
        "    for i in range(X.shape[0]):\n",
        "        beta_list = []\n",
        "        for k_i in model.k:\n",
        "            beta_i = np.exp(sum(model.beta[k_i, f]()*X[i, f] for f in model.F))\n",
        "            beta_list.append(beta_i)\n",
        "        pred_all = [b/sum(beta_list) for b in beta_list]\n",
        "        pred.append(pred_all.index(max(pred_all)))\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "6mLTOLmEINU-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real Dataset"
      ],
      "metadata": {
        "id": "Y04xLvRCBmrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR"
      ],
      "metadata": {
        "id": "lu92NsOVHZ2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load a binary classification dataset\n",
        "\n",
        "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "metadata": {
        "id": "PUOpbWMSqzzJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train logistic regression model using ipopt with regularization weight of 0.5\n",
        "\n",
        "lr_model = logistic_regression(X_train, y_train, w_reg=0.5)\n",
        "solver = SolverFactory('ipopt')\n",
        "# solver.options['halt_on_ampl_error_solver'] = 'yes'\n",
        "results = solver.solve(lr_model, tee=True)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XztPqtUrQbt",
        "outputId": "b2896534-1a93-4258-aa3c-11ff0f5394e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ipopt 3.12.13: \n",
            "\n",
            "******************************************************************************\n",
            "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
            " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
            "         For more information visit http://projects.coin-or.org/Ipopt\n",
            "******************************************************************************\n",
            "\n",
            "This is Ipopt version 3.12.13, running with linear solver mumps.\n",
            "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
            "\n",
            "Number of nonzeros in equality constraint Jacobian...:        0\n",
            "Number of nonzeros in inequality constraint Jacobian.:        0\n",
            "Number of nonzeros in Lagrangian Hessian.............:      465\n",
            "\n",
            "Total number of variables............................:       30\n",
            "                     variables with only lower bounds:        0\n",
            "                variables with lower and upper bounds:        0\n",
            "                     variables with only upper bounds:        0\n",
            "Total number of equality constraints.................:        0\n",
            "Total number of inequality constraints...............:        0\n",
            "        inequality constraints with only lower bounds:        0\n",
            "   inequality constraints with lower and upper bounds:        0\n",
            "        inequality constraints with only upper bounds:        0\n",
            "\n",
            "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
            "   0  2.9528070e+02 0.00e+00 1.00e+02  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
            "   1  1.2864262e+02 0.00e+00 5.32e+01  -1.0 2.03e+00    -  1.00e+00 1.00e+00f  1\n",
            "   2  8.9914001e+01 0.00e+00 2.85e+01  -1.0 4.66e-01    -  1.00e+00 1.00e+00f  1\n",
            "   3  6.8945780e+01 0.00e+00 1.54e+01  -1.0 5.04e-01    -  1.00e+00 1.00e+00f  1\n",
            "   4  5.4048782e+01 0.00e+00 8.75e+00  -1.0 1.13e+00    -  1.00e+00 1.00e+00f  1\n",
            "   5  4.7505989e+01 0.00e+00 3.15e+00  -1.0 6.14e-01    -  1.00e+00 1.00e+00f  1\n",
            "   6  4.5980365e+01 0.00e+00 6.06e-01  -1.0 2.29e-01    -  1.00e+00 1.00e+00f  1\n",
            "   7  4.5863889e+01 0.00e+00 2.90e-02  -1.7 6.89e-02    -  1.00e+00 1.00e+00f  1\n",
            "   8  4.5863099e+01 0.00e+00 7.22e-05  -2.5 5.61e-03    -  1.00e+00 1.00e+00f  1\n",
            "   9  4.5863099e+01 0.00e+00 5.19e-09  -5.7 3.72e-05    -  1.00e+00 1.00e+00f  1\n",
            "\n",
            "Number of Iterations....: 9\n",
            "\n",
            "                                   (scaled)                 (unscaled)\n",
            "Objective...............:   1.1724085541838235e-01    4.5863098508550671e+01\n",
            "Dual infeasibility......:   5.1944111044531984e-09    2.0319860967177306e-06\n",
            "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
            "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
            "Overall NLP error.......:   5.1944111044531984e-09    2.0319860967177306e-06\n",
            "\n",
            "\n",
            "Number of objective function evaluations             = 10\n",
            "Number of objective gradient evaluations             = 10\n",
            "Number of equality constraint evaluations            = 0\n",
            "Number of inequality constraint evaluations          = 0\n",
            "Number of equality constraint Jacobian evaluations   = 0\n",
            "Number of inequality constraint Jacobian evaluations = 0\n",
            "Number of Lagrangian Hessian evaluations             = 9\n",
            "Total CPU secs in IPOPT (w/o function evaluations)   =      0.013\n",
            "Total CPU secs in NLP function evaluations           =      0.026\n",
            "\n",
            "EXIT: Optimal Solution Found.\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Problem: \n",
            "- Lower bound: -inf\n",
            "  Upper bound: inf\n",
            "  Number of objectives: 1\n",
            "  Number of constraints: 0\n",
            "  Number of variables: 30\n",
            "  Sense: unknown\n",
            "Solver: \n",
            "- Status: ok\n",
            "  Message: Ipopt 3.12.13\\x3a Optimal Solution Found\n",
            "  Termination condition: optimal\n",
            "  Id: 0\n",
            "  Error rc: 0\n",
            "  Time: 0.08697676658630371\n",
            "Solution: \n",
            "- number of solutions: 0\n",
            "  number of solutions displayed: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train accuracy: \", accuracy_score(y_train, lr_predict(lr_model, X_train)))\n",
        "print(\"Test accuracy: \", accuracy_score(y_test, lr_predict(lr_model, X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aymvIU831yuU",
        "outputId": "0d22c3d0-eccd-4340-d666-306e90bf0e45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy:  0.960093896713615\n",
            "Test accuracy:  0.958041958041958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax"
      ],
      "metadata": {
        "id": "K2Y-LA7SHlH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load Iris dataset\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "metadata": {
        "id": "kiEatAQY2Oup"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_model = softmax_regression(X_train, y_train, 3, w_reg=0.5)\n",
        "solver = SolverFactory('ipopt')\n",
        "results = solver.solve(softmax_model, tee=True)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA5d22fyHhRR",
        "outputId": "b67b8b6a-6b64-48f1-e42b-55e43ed3d518"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ipopt 3.12.13: \n",
            "\n",
            "******************************************************************************\n",
            "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
            " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
            "         For more information visit http://projects.coin-or.org/Ipopt\n",
            "******************************************************************************\n",
            "\n",
            "This is Ipopt version 3.12.13, running with linear solver mumps.\n",
            "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
            "\n",
            "Number of nonzeros in equality constraint Jacobian...:        0\n",
            "Number of nonzeros in inequality constraint Jacobian.:        0\n",
            "Number of nonzeros in Lagrangian Hessian.............:       78\n",
            "\n",
            "Total number of variables............................:       12\n",
            "                     variables with only lower bounds:        0\n",
            "                variables with lower and upper bounds:        0\n",
            "                     variables with only upper bounds:        0\n",
            "Total number of equality constraints.................:        0\n",
            "Total number of inequality constraints...............:        0\n",
            "        inequality constraints with only lower bounds:        0\n",
            "   inequality constraints with lower and upper bounds:        0\n",
            "        inequality constraints with only upper bounds:        0\n",
            "\n",
            "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
            "   0  1.2304458e+02 0.00e+00 8.79e+01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
            "   1  5.7259629e+01 0.00e+00 4.21e+01  -1.0 1.14e+00    -  1.00e+00 1.00e+00f  1\n",
            "   2  4.0915778e+01 0.00e+00 1.04e+01  -1.0 5.50e-01    -  1.00e+00 1.00e+00f  1\n",
            "   3  3.1253983e+01 0.00e+00 4.08e+00  -1.0 8.49e-01    -  1.00e+00 1.00e+00f  1\n",
            "   4  2.9864880e+01 0.00e+00 8.92e-01  -1.0 4.66e-01    -  1.00e+00 1.00e+00f  1\n",
            "   5  2.9834653e+01 0.00e+00 5.61e-02  -1.7 6.67e-02    -  1.00e+00 1.00e+00f  1\n",
            "   6  2.9834570e+01 0.00e+00 3.63e-04  -2.5 2.97e-03    -  1.00e+00 1.00e+00f  1\n",
            "   7  2.9834570e+01 0.00e+00 9.99e-09  -5.7 1.25e-05    -  1.00e+00 1.00e+00f  1\n",
            "\n",
            "Number of Iterations....: 7\n",
            "\n",
            "                                   (scaled)                 (unscaled)\n",
            "Objective...............:   2.9834569712659391e+01    2.9834569712659391e+01\n",
            "Dual infeasibility......:   9.9884562010377209e-09    9.9884562010377209e-09\n",
            "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
            "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
            "Overall NLP error.......:   9.9884562010377209e-09    9.9884562010377209e-09\n",
            "\n",
            "\n",
            "Number of objective function evaluations             = 8\n",
            "Number of objective gradient evaluations             = 8\n",
            "Number of equality constraint evaluations            = 0\n",
            "Number of inequality constraint evaluations          = 0\n",
            "Number of equality constraint Jacobian evaluations   = 0\n",
            "Number of inequality constraint Jacobian evaluations = 0\n",
            "Number of Lagrangian Hessian evaluations             = 7\n",
            "Total CPU secs in IPOPT (w/o function evaluations)   =      0.007\n",
            "Total CPU secs in NLP function evaluations           =      0.003\n",
            "\n",
            "EXIT: Optimal Solution Found.\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Problem: \n",
            "- Lower bound: -inf\n",
            "  Upper bound: inf\n",
            "  Number of objectives: 1\n",
            "  Number of constraints: 0\n",
            "  Number of variables: 12\n",
            "  Sense: unknown\n",
            "Solver: \n",
            "- Status: ok\n",
            "  Message: Ipopt 3.12.13\\x3a Optimal Solution Found\n",
            "  Termination condition: optimal\n",
            "  Id: 0\n",
            "  Error rc: 0\n",
            "  Time: 0.10255980491638184\n",
            "Solution: \n",
            "- number of solutions: 0\n",
            "  number of solutions displayed: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train accuracy: \", accuracy_score(y_train, softmax_predict(softmax_model, X_train)))\n",
        "print(\"Test accuracy: \", accuracy_score(y_test, softmax_predict(softmax_model, X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrFM08CHHkj0",
        "outputId": "a51ea75b-0ca7-4d27-acc9-742346c1d5e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy:  0.9821428571428571\n",
            "Test accuracy:  0.9210526315789473\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Softmax_Pyomo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}